{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabanitaha/data-mining-2-/blob/main/REVIEW_Lab_Building_Advanced_Transformers_v1_Answered_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c9567f-d149-4027-960c-509ab962f034"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fe48ef1-ad8c-4865-939d-737949d5403f"
      },
      "source": [
        "# **Lab: Building Advanced Transformers**\n",
        "\n",
        "**Estimated time needed:  30 minutes**  \n",
        "\n",
        "In this lab, you will implement and experiment with advanced Transformer models using Keras.\n",
        "\n",
        "**Learning objectives:**\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "- Understand the core components of a Transformer architecture.\n",
        "- Implement a multi-head self-attention mechanism from scratch.\n",
        "- Train and evaluate a Transformer for time series prediction.\n",
        "- Handle preprocessing and scaling for time series data effectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9085021a-0940-4cce-b377-55c6ed324689"
      },
      "source": [
        "## What is a Transformer?\n",
        "\n",
        "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
        "\n",
        "### Key Components:\n",
        "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
        "- **Positional Encoding:** Injects information about the position of input tokens.\n",
        "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
        "- **Feedforward Layers:** Process the attended information.\n",
        "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
        "\n",
        "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
        "\n",
        "**Next:** You will implement parts of this architecture step-by-step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc0932f5-ca9b-4c8e-8071-fb7602700393"
      },
      "source": [
        "## Step-by-Step Instructions:\n",
        "\n",
        "### Step 1: Import necessary libraries\n",
        "\n",
        "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57093c77-cb7a-49b3-b5b4-0bd3fe7d0dac",
        "outputId": "7adaf194-b074-444f-aa23-ac3b1619866c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow pyarrow\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install requests\n",
        "\n"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f1250cc-a6d2-442b-8c5f-87f880c41425"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5555bbf4-0d2b-494c-876d-163f73adfe38"
      },
      "source": [
        "####  Setup the Environment to generate synthetic stock price data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad25744-9da7-407e-aafb-7727191155c5",
        "outputId": "c0c06b1d-827d-4abe-bb58-9d2f31e73855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic stock_prices.csv created and loaded.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a synthetic stock price dataset\n",
        "np.random.seed(42)\n",
        "data_length = 2000  # Adjust data length as needed\n",
        "trend = np.linspace(100, 200, data_length)\n",
        "noise = np.random.normal(0, 2, data_length)\n",
        "synthetic_data = trend + noise\n",
        "\n",
        "# Create a DataFrame and save as 'stock_prices.csv'\n",
        "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
        "data.to_csv('stock_prices.csv', index=False)\n",
        "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd5437c3-535c-4fc9-897d-f90b931a0253",
        "outputId": "be3b7968-dbc2-4850-e34e-5e154a0a8996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (1899, 100, 1)\n",
            "Shape of Y: (1899,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('stock_prices.csv')\n",
        "data = data[['Close']].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare the data for training\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        a = data[i:(i+time_step), 0]\n",
        "        X.append(a)\n",
        "        Y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "X, Y = create_dataset(data, time_step)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e4b5d6f-1d42-4ab5-b26a-99202a05ed2e"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "`tensorflow` is the main library for machine learning in Python.  \n",
        "\n",
        "`stock_prices.csv` is the data set that is loaded.\n",
        "\n",
        "`MinMaxScaler` method is used to normalize the data.  \n",
        "\n",
        "`create_dataset`method is used to prepare the data for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d9cc83-c862-468a-9095-33d79366b3e6"
      },
      "source": [
        "### Step 2: Implement Multi-Head Self-Attention\n",
        "\n",
        "Define the Multi-Head Self-Attention mechanism.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a5493e3-c54b-4c7b-b91f-e860cde8076f"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        ""
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30cc2f47-4ce0-474e-93b6-7a472cbda8eb"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously.\n",
        "\n",
        "- The attention parameter computes the attention scores and weighted sum of the values.\n",
        "\n",
        "- The split_heads parameter splits the input into multiple heads for parallel attention computation.\n",
        "\n",
        "- The call method applies the self-attention mechanism and combines the heads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310949fe-6515-463f-b269-4e0e8d5f7298"
      },
      "source": [
        "### Step 3: Implement Transformer block\n",
        "\n",
        "Define the Transformer block.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48bd3693-2152-4a24-bced-b5fcc2b93ebb"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "009b3148-bfac-4d31-83cb-150f3bdc0eee"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
        "\n",
        "- Dropout is used to prevent overfitting.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "268a11b0-cbc9-46ce-bec2-f6b753869d26"
      },
      "source": [
        "### Step 4: Implement Encoder Layer\n",
        "\n",
        "Define the Encoder layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c8fee5e-d3a2-42d8-9ebc-c32501d506aa"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n"
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77515712-2fdb-4145-bf20-40370d382697"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\n",
        "\n",
        "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\n",
        "\n",
        "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53aa4eb1-ed2d-4e5f-a6c3-3cb3fbf97c3a"
      },
      "source": [
        "### Step 5: Implement Transformer encoder\n",
        "\n",
        "Define the Transformer Encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645323a2-b3e6-4d5c-855f-bd26e8725d60",
        "outputId": "b5365d3e-910d-4edb-97e4-cd65ad0a6528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 128)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
        "\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = inputs\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "inputs = tf.random.uniform((1, 100, embed_dim))\n",
        "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training'\n",
        "print(outputs.shape)  # Should print (1, 100, 128)"
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b5887f5-beb2-4896-ac61-5aa3b1a8b43f"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a56ba42-9248-4dd6-8cd0-5182562a6ab5"
      },
      "source": [
        "### Step 6: Build and Compile the Transformer model\n",
        "\n",
        "Integrate the Transformer Encoder into a complete model for sequential data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "bcbf4111-b2e8-4b0c-b625-20095535d9f9",
        "outputId": "c2a59308-1912-434f-bfc5-d2bee3e2a211"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the necessary parameters\n",
        "\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "# Define the Transformer Encoder\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X.shape[1], X.shape[2])\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Project the inputs to the embed_dim\n",
        "x = tf.keras.layers.Dense(embed_dim)(inputs)\n",
        "encoder_outputs = transformer_encoder(x)\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "outputs = tf.keras.layers.Dense(1)(flatten)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "866c5677-9d64-4761-87c3-0428ddbd7d8e"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
        "\n",
        "- The model is then compiled with the Adam optimizer and mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e650c957-3d8d-4a63-839f-2f1121c439a6"
      },
      "source": [
        "### Step 7: Train the Transformer model\n",
        "\n",
        "Train the model on the prepared dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b88ba571-72b8-4744-bdf5-c540e0d88124",
        "outputId": "f111e230-4d54-4e85-e8f5-2ec294949d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 618ms/step - loss: 11.0080\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 608ms/step - loss: 0.1893\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 602ms/step - loss: 0.1666\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 609ms/step - loss: 0.1915\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 614ms/step - loss: 0.1475\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 597ms/step - loss: 0.1322\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 616ms/step - loss: 0.1483\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 612ms/step - loss: 0.1260\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 611ms/step - loss: 0.0932\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 616ms/step - loss: 0.1170\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 593ms/step - loss: 0.1416\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 613ms/step - loss: 0.1604\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 612ms/step - loss: 0.0722\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 612ms/step - loss: 0.0587\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 596ms/step - loss: 0.0662\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 610ms/step - loss: 0.0990\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 610ms/step - loss: 0.0455\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 605ms/step - loss: 0.0259\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 605ms/step - loss: 0.0220\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 599ms/step - loss: 0.0172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78dab6e0fdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57e8051c-8d75-44cb-ae77-ce8e6a1ea8bc"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8eff4c1-817e-4c0e-bc4d-6a8225e1ac63"
      },
      "source": [
        "### Step 8: Evaluate and Make Predictions\n",
        "\n",
        "Evaluate the model's performance and make predictions on the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "8a2c475e-7eca-43c5-8f9f-5c251fad62ec",
        "outputId": "d62d271e-c755-4547-8375-f6217571c96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Prepare true values for comparison\n",
        "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
        "\n",
        "# Plot the predictions vs true values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(true_values, label='True Data')\n",
        "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
        "plt.show()\n"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54508aee-14a9-4415-900d-d60a0ab6a123"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler.\n",
        "\n",
        "- The true data and predictions are plotted to visualize the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d67c9e0-704c-4885-96a1-2f0583b656bc"
      },
      "source": [
        "## Practice Exercises:\n",
        "\n",
        " ### Exercise 1: Add dropout to the Transformer model\n",
        "\n",
        " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Add a dropout layer after the Flatten layer in the model.\n",
        "\n",
        "- Set the dropout rate to 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "7afb541b-ff6f-4d84-969e-acc846ddf708",
        "outputId": "ec31ed81-bdc9-4ad2-c2a4-c70b552fb466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Write your code here.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Embedding, LayerNormalization\n",
        "\n",
        "# Example input shape and vocabulary size\n",
        "input_shape = (100,)\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_shape[0]),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),  # ✅ Dropout layer added after Flatten to prevent overfitting\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca356342-d1da-4811-adc8-520b2cbf9de1"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "  \n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "  \n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  \n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "  \n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "  \n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9_kj19IIfVb",
        "outputId": "60b2ccc0-d94f-4792-f386-bb0970f62db6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 625ms/step - loss: 4.1986\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 622ms/step - loss: 0.8329\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 619ms/step - loss: 0.3274\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 617ms/step - loss: 0.1101\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 622ms/step - loss: 0.0688\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 623ms/step - loss: 0.0555\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 613ms/step - loss: 0.0405\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 624ms/step - loss: 0.0354\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 623ms/step - loss: 0.0355\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 623ms/step - loss: 0.0336\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 620ms/step - loss: 0.0329\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 619ms/step - loss: 0.0292\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 620ms/step - loss: 0.0269\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 624ms/step - loss: 0.0252\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 624ms/step - loss: 0.0280\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 624ms/step - loss: 0.0239\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 624ms/step - loss: 0.0259\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 606ms/step - loss: 0.0246\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 624ms/step - loss: 0.0164\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 635ms/step - loss: 0.0155\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step - loss: 0.0044\n",
            "Test loss: 0.003507130080834031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72dc58a7-057f-4582-b0a2-38ecae4fc6d7"
      },
      "source": [
        "### Exercise 2: Experiment with different batch sizes\n",
        "\n",
        "**Objective: Observe the impact of different batch sizes on model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Train the model with a batch size of 16.\n",
        "\n",
        "- Train the model with a batch size of 64.\n",
        "\n",
        "- Compare the training time and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e9d62a0-821f-4050-a59a-e10c6155e799",
        "outputId": "a8e3e525-986a-462e-f765-45451881d7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size 16 - Accuracy: 1.0000, Time: 5.46s\n",
            "Batch size 64 - Accuracy: 1.0000, Time: 3.46s\n"
          ]
        }
      ],
      "source": [
        "## Write your code here.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Embedding\n",
        "\n",
        "# Simulated data\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "input_shape = (100,)\n",
        "num_samples = 1000\n",
        "\n",
        "X = np.random.randint(0, vocab_size, size=(num_samples, input_shape[0]))\n",
        "y = np.random.randint(0, 2, size=(num_samples,))\n",
        "\n",
        "# Model creation function\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train and evaluate for batch size 16\n",
        "model_16 = create_model()\n",
        "start_16 = time.time()\n",
        "history_16 = model_16.fit(X, y, batch_size=16, epochs=3, verbose=0)\n",
        "end_16 = time.time()\n",
        "loss_16, acc_16 = model_16.evaluate(X, y, verbose=0)\n",
        "\n",
        "# Train and evaluate for batch size 64\n",
        "model_64 = create_model()\n",
        "start_64 = time.time()\n",
        "history_64 = model_64.fit(X, y, batch_size=64, epochs=3, verbose=0)\n",
        "end_64 = time.time()\n",
        "loss_64, acc_64 = model_64.evaluate(X, y, verbose=0)\n",
        "\n",
        "# Display results\n",
        "print(f\"Batch size 16 - Accuracy: {acc_16:.4f}, Time: {end_16 - start_16:.2f}s\")\n",
        "print(f\"Batch size 64 - Accuracy: {acc_64:.4f}, Time: {end_64 - start_64:.2f}s\")\n"
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2b52fb1-841e-4354-b73c-f5bd9bc8c4da"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dropout, Dense\n",
        "\n",
        "# Input settings\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "input_shape = (100,)\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate matching input and output shapes\n",
        "X = np.random.randint(0, vocab_size, size=(num_samples, input_shape[0]))\n",
        "y = np.random.randint(0, 2, size=(num_samples,))\n",
        "\n",
        "# Create the model definition\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train with batch size 16\n",
        "model_16 = create_model()\n",
        "model_16.fit(X, y, batch_size=16, epochs=3, verbose=0)\n",
        "loss_16 = model_16.evaluate(X, y, verbose=0)\n",
        "\n",
        "# Train with batch size 64\n",
        "model_64 = create_model()\n",
        "model_64.fit(X, y, batch_size=64, epochs=3, verbose=0)\n",
        "loss_64 = model_64.evaluate(X, y, verbose=0)\n",
        "\n",
        "print(f\"Test loss with batch size 16: {loss_16[0]:.4f}\")\n",
        "print(f\"Test loss with batch size 64: {loss_64[0]:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYMXIWaQL3mN",
        "outputId": "45754c72-1b03-4f8b-ede1-d9f90b321539"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss with batch size 16: 0.0047\n",
            "Test loss with batch size 64: 0.1138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c6ca2ca-fa3b-419f-b968-db4fc397c162"
      },
      "source": [
        "### Exercise 3: Use a different activation function\n",
        "\n",
        " **Objective: Understand how different activation functions impact the model performance.**\n",
        "\n",
        " Instructions:\n",
        "\n",
        "- Change the activation function of the Dense layer to `tanh`.\n",
        "\n",
        "- Train and evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fc2f6b-ff5d-45cf-9913-5eed4cd18d82",
        "outputId": "30cc84c3-7719-4a76-a2fb-bcfc44e85105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0079, Test accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "## Write your code here.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dropout, Dense\n",
        "\n",
        "# Example input settings\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "input_shape = (100,)\n",
        "num_samples = 1000\n",
        "\n",
        "# Create synthetic dataset with matching input and label shapes\n",
        "X = np.random.randint(0, vocab_size, size=(num_samples, input_shape[0]))\n",
        "y = np.random.randint(0, 2, size=(num_samples,))\n",
        "\n",
        "# Build the model with tanh activation\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='tanh'),       # Activation changed here to tanh\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=32, epochs=3, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")\n"
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a87742a7-6c71-4d70-9c03-b0b81a869fff"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')\n",
        "\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
        "\n",
        "# Sample input setup\n",
        "input_shape = (100,)\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "\n",
        "# Fix mismatched sample lengths\n",
        "X = X[:min(len(X), len(y))]\n",
        "y = y[:min(len(X), len(y))]\n",
        "\n",
        "# Define the input and embedding\n",
        "inputs = Input(shape=input_shape)\n",
        "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
        "\n",
        "# Flatten the embedding output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Optional: Add dropout layer if needed\n",
        "# x = Dropout(0.5)(x)\n",
        "\n",
        "# Dense layer with tanh activation (Exercise 3)\n",
        "outputs = Dense(1, activation='tanh')(x)\n",
        "\n",
        "# Build and compile the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate\n",
        "loss = model.evaluate(X, y)\n",
        "print(f\"Test loss with tanh activation: {loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI2HdfyEPbRq",
        "outputId": "81c188c2-d230-4f26-fecd-72dca3665b59"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.4828\n",
            "Epoch 2/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1068\n",
            "Epoch 3/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0211\n",
            "Epoch 4/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0097\n",
            "Epoch 5/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0070\n",
            "Epoch 6/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107\n",
            "Epoch 7/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0280\n",
            "Epoch 8/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0637\n",
            "Epoch 9/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0566\n",
            "Epoch 10/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0399\n",
            "Epoch 11/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0278\n",
            "Epoch 12/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0232\n",
            "Epoch 13/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0254\n",
            "Epoch 14/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0281\n",
            "Epoch 15/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0326\n",
            "Epoch 16/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0293\n",
            "Epoch 17/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0249\n",
            "Epoch 18/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0228\n",
            "Epoch 19/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0208\n",
            "Epoch 20/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0179\n",
            "Test loss with tanh activation: 0.016954420134425163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d517b5e4-01f0-466d-88aa-80708f52264f"
      },
      "source": [
        "## Conclusion\n",
        "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edafaf7b-0e83-4d03-910b-587b5d5578c8"
      },
      "source": [
        "Copyright © IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}