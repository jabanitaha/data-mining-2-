{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabanitaha/data-mining-2-/blob/main/DL0101EN_4_1_CNN_Keras_Answered_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a259076-5a31-482e-b598-0138c6bfe11a"
      },
      "source": [
        "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
        "\n",
        "# Convolutional Neural Networks with Keras\n",
        "\n",
        "Estimated time needed **30** mins\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a86cd7f-c191-4c78-92a5-2479b13cba2b"
      },
      "source": [
        "In this lab, we will learn how to use the Keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7c948e3-995c-45c0-86f0-8916fbee6b02"
      },
      "source": [
        "## Objectives for this Notebook    \n",
        "* How to use the Keras library to build convolutional neural networks\n",
        "* Convolutional neural network with one set of convolutional and pooling layers\n",
        "* Convolutional neural network with two sets of convolutional and pooling layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82e267c1-74e4-4f30-be50-15b58d592add"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "      \n",
        "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a>   \n",
        "2. <a href=\"#Convolutional-Neural-Network-with-One-Set-of-Convolutional-and-Pooling-Layers\">Convolutional Neural Network with One Set of Convolutional and Pooling Layers</a>  \n",
        "3. <a href=\"#Convolutional-Neural-Network-with-Two-Sets-of-Convolutional-and-Pooling-Layers\">Convolutional Neural Network with Two Sets of Convolutional and Pooling Layers</a>  \n",
        "\n",
        "</font>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2725718-c839-403f-8017-236d760c20c0"
      },
      "source": [
        "### Install the necessary libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5860a2ee-ec49-4add-ad79-556d6960495a"
      },
      "source": [
        "Let's start by installing the keras libraries and the packages that we would need to build a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc5e450c-e81e-42b1-a564-7d59bd960067",
        "outputId": "cd20e1eb-b519-4bb5-c012-38c31d547bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: tensorflow_cpu==2.18.0 in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_cpu==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow_cpu==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow_cpu==2.18.0) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow_cpu==2.18.0) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow_cpu==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow_cpu==2.18.0) (0.1.2)\n",
            "Requirement already satisfied: matplotlib==3.9.2 in /usr/local/lib/python3.11/dist-packages (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# All Libraries required for this lab are listed below. The libraries need to be installed on Skills Network Labs.\n",
        "# If you run this notebook on a different environment, e.g. your desktop, you may want to install these.\n",
        "!pip install numpy==2.0.2\n",
        "!pip install pandas==2.2.2\n",
        "!pip install tensorflow_cpu==2.18.0\n",
        "!pip install matplotlib==3.9.2"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df48ab35-3ce3-4d73-9e9f-142c1c272773"
      },
      "source": [
        "#### Suppress the tensorflow warning messages\n",
        "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
        "You may want to **comment out** these lines if you are using the GPU architechture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4d79a7c-6cbc-4b7c-8f6e-23c4d3dbec4f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8cb5959-7529-4024-aabe-711e02b1a573"
      },
      "source": [
        "## Import Keras and Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54f7f5de-dd4f-4160-97a7-41fc13358596"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ae6ee1f-c5f9-4136-a661-d0ecad7bc618"
      },
      "source": [
        "When working with convolutional neural networks in particular, we will need additional packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59965020-f741-41d0-8b70-00253641ff4c"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D # to add convolutional layers\n",
        "from keras.layers import MaxPooling2D # to add pooling layers\n",
        "from keras.layers import Flatten # to flatten data for fully connected layers"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4be0cd5-9e2a-44f7-a6de-1fdc46923fb4"
      },
      "source": [
        "## Convolutional Neural Network with One Set of Convolutional and Pooling Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21cd5320-20a6-4e90-89be-81af7990a4c5",
        "outputId": "235fe4fa-f91b-456a-f752-f78953423055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# import data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82a804cb-2ea6-4925-94a1-ef4ba5a2ef1d"
      },
      "source": [
        "Let's normalize the pixel values to be between 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26b2fc47-fbfb-42ce-bfe7-d1cda99d4988"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data"
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58622fd9-b0ff-408c-baf5-4db94f8a0a97"
      },
      "source": [
        "Next, let's convert the target variable into binary categories\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c01c40ef-75ba-4c87-954a-4f5ecef7b41f"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories"
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c42c05a-ae9e-44bc-ab58-5b5c55c6cc43"
      },
      "source": [
        "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "678716df-28c6-4944-872b-2ab253d7ea68"
      },
      "outputs": [],
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(28, 28, 1)))\n",
        "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d94c41fa-0fae-482c-b4f5-0729d31569c2"
      },
      "source": [
        "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "095aa859-c641-4d6d-abb6-a1712a64f89b",
        "outputId": "3b887e47-6663-4cdd-f082-a263a3ccc786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 23s - 76ms/step - accuracy: 0.9118 - loss: 0.3084 - val_accuracy: 0.9671 - val_loss: 0.1208\n",
            "Epoch 2/10\n",
            "300/300 - 40s - 133ms/step - accuracy: 0.9727 - loss: 0.0947 - val_accuracy: 0.9804 - val_loss: 0.0675\n",
            "Epoch 3/10\n",
            "300/300 - 19s - 64ms/step - accuracy: 0.9815 - loss: 0.0630 - val_accuracy: 0.9834 - val_loss: 0.0539\n",
            "Epoch 4/10\n",
            "300/300 - 21s - 69ms/step - accuracy: 0.9858 - loss: 0.0477 - val_accuracy: 0.9856 - val_loss: 0.0464\n",
            "Epoch 5/10\n",
            "300/300 - 22s - 72ms/step - accuracy: 0.9888 - loss: 0.0367 - val_accuracy: 0.9860 - val_loss: 0.0425\n",
            "Epoch 6/10\n",
            "300/300 - 40s - 134ms/step - accuracy: 0.9903 - loss: 0.0317 - val_accuracy: 0.9867 - val_loss: 0.0397\n",
            "Epoch 7/10\n",
            "300/300 - 21s - 70ms/step - accuracy: 0.9928 - loss: 0.0250 - val_accuracy: 0.9867 - val_loss: 0.0421\n",
            "Epoch 8/10\n",
            "300/300 - 19s - 64ms/step - accuracy: 0.9937 - loss: 0.0205 - val_accuracy: 0.9863 - val_loss: 0.0395\n",
            "Epoch 9/10\n",
            "300/300 - 22s - 73ms/step - accuracy: 0.9949 - loss: 0.0179 - val_accuracy: 0.9876 - val_loss: 0.0400\n",
            "Epoch 10/10\n",
            "300/300 - 39s - 132ms/step - accuracy: 0.9957 - loss: 0.0146 - val_accuracy: 0.9877 - val_loss: 0.0401\n",
            "Accuracy: 0.9876999855041504 \n",
            " Error: 1.230001449584961\n"
          ]
        }
      ],
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdadb672-3dd5-47c8-b2aa-b573faec12ab"
      },
      "source": [
        "------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8346bc8d-b06d-4e59-ab6d-38ab51f7e3a2"
      },
      "source": [
        "## Convolutional Neural Network with Two Sets of Convolutional and Pooling Layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed6adec1-b389-4d45-a94b-c3f378106a02"
      },
      "source": [
        "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1238bc6e-7594-48f2-b239-83fd36c4838d"
      },
      "outputs": [],
      "source": [
        "def convolutional_model():\n",
        "\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(28, 28, 1)))\n",
        "    model.add(Conv2D(16, (5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad1e634f-0a4a-475b-95da-b6e322a83c46"
      },
      "source": [
        "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c0465aa-295a-49e7-92bb-050edb59e3df",
        "outputId": "08257901-248c-404f-d201-f58f7bc9575d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 23s - 78ms/step - accuracy: 0.8571 - loss: 0.5003 - val_accuracy: 0.9548 - val_loss: 0.1548\n",
            "Epoch 2/10\n",
            "300/300 - 21s - 69ms/step - accuracy: 0.9613 - loss: 0.1287 - val_accuracy: 0.9733 - val_loss: 0.0894\n",
            "Epoch 3/10\n",
            "300/300 - 42s - 141ms/step - accuracy: 0.9739 - loss: 0.0865 - val_accuracy: 0.9787 - val_loss: 0.0675\n",
            "Epoch 4/10\n",
            "300/300 - 41s - 135ms/step - accuracy: 0.9790 - loss: 0.0690 - val_accuracy: 0.9822 - val_loss: 0.0571\n",
            "Epoch 5/10\n",
            "300/300 - 22s - 73ms/step - accuracy: 0.9819 - loss: 0.0586 - val_accuracy: 0.9837 - val_loss: 0.0506\n",
            "Epoch 6/10\n",
            "300/300 - 21s - 69ms/step - accuracy: 0.9846 - loss: 0.0501 - val_accuracy: 0.9866 - val_loss: 0.0415\n",
            "Epoch 7/10\n",
            "300/300 - 42s - 139ms/step - accuracy: 0.9868 - loss: 0.0436 - val_accuracy: 0.9855 - val_loss: 0.0457\n",
            "Epoch 8/10\n",
            "300/300 - 41s - 136ms/step - accuracy: 0.9875 - loss: 0.0398 - val_accuracy: 0.9872 - val_loss: 0.0385\n",
            "Epoch 9/10\n",
            "300/300 - 40s - 133ms/step - accuracy: 0.9891 - loss: 0.0352 - val_accuracy: 0.9854 - val_loss: 0.0418\n",
            "Epoch 10/10\n",
            "300/300 - 22s - 74ms/step - accuracy: 0.9901 - loss: 0.0321 - val_accuracy: 0.9893 - val_loss: 0.0326\n",
            "Accuracy: 0.989300012588501 \n",
            " Error: 1.0699987411499023\n"
          ]
        }
      ],
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1461351b-e85e-431a-94f7-7a803ad091f0"
      },
      "source": [
        "<h3>Practice Exercise 1</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b552fc94-0831-4569-bc0e-c5b9b153b70d"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f01355d9-0484-4b16-8419-fd6e64640806",
        "outputId": "5c6fdf41-e2e9-485a-b587-76f9f55b3971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 40s - 21ms/step - accuracy: 0.9524 - loss: 0.1588 - val_accuracy: 0.9780 - val_loss: 0.0674\n",
            "Epoch 2/5\n",
            "1875/1875 - 39s - 21ms/step - accuracy: 0.9836 - loss: 0.0531 - val_accuracy: 0.9842 - val_loss: 0.0486\n",
            "Epoch 3/5\n",
            "1875/1875 - 41s - 22ms/step - accuracy: 0.9890 - loss: 0.0348 - val_accuracy: 0.9849 - val_loss: 0.0429\n",
            "Epoch 4/5\n",
            "1875/1875 - 42s - 23ms/step - accuracy: 0.9931 - loss: 0.0226 - val_accuracy: 0.9860 - val_loss: 0.0428\n",
            "Epoch 5/5\n",
            "1875/1875 - 37s - 20ms/step - accuracy: 0.9945 - loss: 0.0163 - val_accuracy: 0.9850 - val_loss: 0.0502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79915bd4f650>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Write your answer here\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define a simple CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, verbose=2)\n",
        "\n"
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bb6cc35-d6d9-4d82-97ff-44f59a729e0f"
      },
      "source": [
        "[link text](https://)Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- Your answer is below:\n",
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=1024, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a03ad9b-825d-47ae-be77-e3bf1885c08e"
      },
      "source": [
        "<h3>Practice Exercise 2</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5989a3e9-0d9c-4769-a33d-fc22447a82bd"
      },
      "source": [
        "\n",
        "# Evaluate the trained model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"✅ Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9e95cec-0929-4e21-82f2-88b829c59460",
        "outputId": "ec5f2861-fae4-4be4-aa0a-c363240d0ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test Accuracy: 0.9850\n"
          ]
        }
      ],
      "source": [
        "# Write your answer here\n",
        "\n",
        "# Evaluate the trained model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"✅ Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51c6e6da-7d0d-4090-9fb8-98f22d051bdb"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- Your answer is below:\n",
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25, batch_size=1024, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))\n",
        "\n",
        "\n",
        "    -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "844cc9d3-9e42-433a-9767-c03f0c1eb77d"
      },
      "source": [
        "### Thank you for completing this lab!\n",
        "\n",
        "This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e3e2e36-9537-40c4-80bc-24e056e0b3c0"
      },
      "source": [
        "<!--\n",
        "## Change Log\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2024-11-20  | 3.0  | Aman  |  Updated the library versions to current |\n",
        "| 2020-09-21  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab20d78f-6c72-4aad-b35d-e2e770c39d5e"
      },
      "source": [
        "## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "prev_pub_hash": "cf25684b5f40b85f8cce20a89cf822f405779387881f3fd281fbe1317debe407",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}